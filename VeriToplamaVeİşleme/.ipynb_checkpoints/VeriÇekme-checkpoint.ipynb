{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fb4009b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 processed.\n",
      "Page 2 processed.\n",
      "Page 3 processed.\n",
      "Page 4 processed.\n",
      "Page 5 processed.\n",
      "Page 6 processed.\n",
      "Page 7 processed.\n",
      "Page 8 processed.\n",
      "Page 9 processed.\n",
      "Page 10 processed.\n",
      "Page 11 processed.\n",
      "Page 12 processed.\n",
      "Page 13 processed.\n",
      "Page 14 processed.\n",
      "Page 15 processed.\n",
      "Page 16 processed.\n",
      "Page 17 processed.\n",
      "Page 18 processed.\n",
      "Page 19 processed.\n",
      "Page 20 processed.\n",
      "Page 21 processed.\n",
      "Page 22 processed.\n",
      "Page 23 processed.\n",
      "Page 24 processed.\n",
      "Page 25 processed.\n",
      "Page 26 processed.\n",
      "Page 27 processed.\n",
      "Page 28 processed.\n",
      "Page 29 processed.\n",
      "Page 30 processed.\n",
      "Page 31 processed.\n",
      "Page 32 processed.\n",
      "Page 33 processed.\n",
      "Page 34 processed.\n",
      "Page 35 processed.\n",
      "Page 36 processed.\n",
      "Page 37 processed.\n",
      "Page 38 processed.\n",
      "Page 39 processed.\n",
      "Page 40 processed.\n",
      "Page 41 processed.\n",
      "Page 42 processed.\n",
      "Page 43 processed.\n",
      "Data extraction and conversion to Excel completed.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "base_url = \"https://www.hepsiemlak.com/ankara-kiralik?page={num}\"\n",
    "\n",
    "# Function to clean up text using regular expressions\n",
    "def clean_text(text):\n",
    "    replacements = {\n",
    "        \" Yaşında\": \"\",\n",
    "        \" m²\": \"\",\n",
    "        \". Kat\": \"\",\n",
    "        \"Yüksek Giriş\": \"1\",\n",
    "        \"Çatı Katı\": \"4\",\n",
    "        \"Giriş Katı\": \"1\",\n",
    "        \"Ara Kat\": \"2\",\n",
    "        \"Teras Katı\": \"5\",\n",
    "        \"En Üst Kat\": \"5\",\n",
    "        \"Sıfır Bina\": \"0\",\n",
    "        \"Bahçe Katı\": \"1\",\n",
    "        \"21 ve üzeri\": \"21\",\n",
    "        \"Bodrum ve Zemin\": \"1\",\n",
    "        \"Zemin\": \"1\",\n",
    "        \"Yarı Bodrum\": \"1\",\n",
    "        \"Bodrum\": \"1\",\n",
    "        \"Stüdyo\": \"1\",\n",
    "        \"Kot \": \"\",\n",
    "        \" TL\": \"\",\n",
    "        \".\": \"\"\n",
    "    }\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    for pattern, replacement in replacements.items():\n",
    "        text = re.sub(re.escape(pattern), replacement, text)\n",
    "\n",
    "    return text\n",
    "\n",
    "# DataFrame oluştur\n",
    "df = pd.DataFrame(columns=[\"Konum\", \"Oda Sayısı\", \"m²\", \"Bina Yaşı\", \"Bulunduğu Kat\", \"Fiyat\"])\n",
    "\n",
    "for page_num in range(3, 46):\n",
    "    url = base_url.format(num=page_num)\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        for div in soup.find_all(\"div\", class_=\"list-view-content\"):\n",
    "            location_div = div.find(\"div\", class_=\"list-view-location\")\n",
    "\n",
    "            if location_div:\n",
    "                location_span = location_div.find_all(\"span\")[2]\n",
    "                index_of_comma = location_span.text.find(',')\n",
    "                result_text = location_span.text[:index_of_comma]\n",
    "                location = clean_text(result_text) if location_span else \"N/A\"\n",
    "            else:\n",
    "                location = \"N/A\"\n",
    "            price_span = div.find(\"span\", class_=\"list-view-price\")\n",
    "            price = clean_text(price_span.text)\n",
    "            spans = div.find(\"span\", class_=\"right celly\").find_all(\"span\")\n",
    "            span_texts = [clean_text(span.text) for span in spans]\n",
    "            \n",
    "            # Yeni veriyi DataFrame'e eklerken sütun adlarını belirt\n",
    "            new_data = pd.DataFrame([[location] + span_texts + [price]], columns=df.columns)\n",
    "            df = pd.concat([df, new_data], ignore_index=True)\n",
    "\n",
    "        print(f\"Page {page_num-2} processed.\")\n",
    "    else:\n",
    "        print(f\"Failed to retrieve page {page_num-2}.\")\n",
    "\n",
    "# Excel dosyasına çevir ve kaydet\n",
    "excel_dosyasi = \"output.xlsx\"\n",
    "df.to_excel(excel_dosyasi, index=False)\n",
    "\n",
    "print(\"Data extraction and conversion to Excel completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8e7c91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
